name: CI Pipeline

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

env:
  AWS_REGION: us-east-2
  AWS_ROLE_ARN: arn:aws:iam::143519759870:role/GitHubActionsMLOpsRole
  AWS_ACCOUNT_ID: "143519759870"

jobs:
  validate-and-build:
    runs-on: ubuntu-latest

    permissions:
      id-token: write # Required for OIDC authentication
      contents: read # Required to checkout code

    steps:
      # Step 1: Checkout repository
      - name: Checkout code
        uses: actions/checkout@v4

      # Step 2: Set up Python
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      # Step 3: Install Python dependencies for testing
      - name: Install test dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests

      # Step 4: Validate services configuration
      # This checks if all service directories exist and have required files
      - name: Validate project structure
        run: |
          echo "Validating microservices structure..."
          for service in inference-service feedback-service model-registry-service evaluation-service retraining-service notification-service model-init-service api-gateway-service; do
            if [ ! -d "services/$service" ]; then
              echo "ERROR: Missing service directory: $service"
              exit 1
            fi
            if [ ! -f "services/$service/Dockerfile" ]; then
              echo "ERROR: Missing Dockerfile for: $service"
              exit 1
            fi
            if [ ! -f "services/$service/requirements.txt" ]; then
              echo "ERROR: Missing requirements.txt for: $service"
              exit 1
            fi
            echo "âœ“ $service validated"
          done
          echo "All services validated successfully!"

      # Step 5: Validate Docker Compose configuration
      - name: Validate docker-compose.yml
        run: |
          echo "Validating docker-compose configuration..."
          docker compose config > /dev/null
          echo "âœ“ docker-compose.yml is valid"

      # Step 6: Build all Docker images
      # This ensures all services can be containerized successfully
      - name: Build Docker images
        run: |
          echo "Building all microservices..."
          docker compose build
          echo "âœ“ All Docker images built successfully"

      # Step 7: List built images for verification
      - name: List Docker images
        run: |
          echo "Built images:"
          docker images | grep -E "(ml-sentiment|inference|feedback|registry|evaluation|retraining|notification|init|gateway)"

      # Step 8: Configure AWS credentials using OIDC
      # This uses GitHub's OIDC provider to assume an IAM role
      # No static credentials needed!
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-CI-${{ github.run_id }}

      # Step 9: Verify AWS authentication
      # Confirms that OIDC authentication was successful
      - name: Verify AWS identity
        run: |
          echo "Verifying AWS credentials..."
          aws sts get-caller-identity
          echo "âœ“ AWS authentication successful"

      # Step 10: Run basic AWS connectivity tests
      # Ensures the assumed role has necessary permissions
      - name: Test AWS permissions
        run: |
          echo "Testing AWS S3 access..."
          aws s3 ls || echo "âš  S3 access not configured (expected for initial setup)"

          echo "Testing AWS SageMaker access..."
          aws sagemaker list-training-jobs --max-results 1 || echo "âš  SageMaker access not configured (expected for initial setup)"

          echo "Testing AWS ECR access..."
          aws ecr describe-repositories || echo "âš  ECR access not configured (expected for initial setup)"

      # Step 11: Clean up Docker resources
      - name: Clean up
        if: always()
        run: |
          echo "Cleaning up Docker resources..."
          docker compose down --volumes --remove-orphans || true
          docker system prune -f || true

  # CD Job: Push images to ECR (runs only on main branch push)
  push-to-ecr:
    runs-on: ubuntu-latest
    needs: validate-and-build
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-CD-${{ github.run_id }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Create ECR repositories if not exist
        run: |
          for service in inference-service feedback-service model-registry-service evaluation-service retraining-service notification-service model-init-service api-gateway-service; do
            aws ecr describe-repositories --repository-names ml-sentiment-$service 2>/dev/null || \
            aws ecr create-repository --repository-name ml-sentiment-$service --image-scanning-configuration scanOnPush=true
            echo "âœ“ Repository ml-sentiment-$service ready"
          done

      - name: Build and push Docker images to ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          echo "Building and pushing images with tag: $IMAGE_TAG"

          # Build and push each service
          for service in inference-service feedback-service model-registry-service evaluation-service retraining-service notification-service model-init-service api-gateway-service; do
            echo "Processing $service..."
            
            # Build image
            docker build -t ml-sentiment-$service:latest ./services/$service
            
            # Tag for ECR
            docker tag ml-sentiment-$service:latest $ECR_REGISTRY/ml-sentiment-$service:$IMAGE_TAG
            docker tag ml-sentiment-$service:latest $ECR_REGISTRY/ml-sentiment-$service:latest
            
            # Push to ECR
            docker push $ECR_REGISTRY/ml-sentiment-$service:$IMAGE_TAG
            docker push $ECR_REGISTRY/ml-sentiment-$service:latest
            
            echo "âœ“ $service pushed to ECR"
          done

          echo "All images pushed successfully!"

      - name: Output image URIs
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          IMAGE_TAG: ${{ github.sha }}
        run: |
          echo "Images pushed to ECR:"
          echo "----------------------------------------"
          for service in inference-service feedback-service model-registry-service evaluation-service retraining-service notification-service model-init-service api-gateway-service; do
            echo "$service: $ECR_REGISTRY/ml-sentiment-$service:$IMAGE_TAG"
          done

  # Infrastructure Deployment with Terraform
  deploy-infrastructure:
    runs-on: ubuntu-latest
    needs: push-to-ecr
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ env.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
          role-session-name: GitHubActions-Terraform-${{ github.run_id }}

      - name: Upload training data to S3
        run: |
          echo "Uploading training data to S3..."
          aws s3 cp Dataset/train_data.csv s3://ml-sentiment-data-${{ env.AWS_ACCOUNT_ID }}/training/train_data.csv --region ${{ env.AWS_REGION }} || echo "Bucket may not exist yet, will be created by Terraform"

      - name: Terraform Init
        working-directory: ./infrastructure
        run: |
          echo "Initializing Terraform..."
          terraform init

      - name: Terraform Validate
        working-directory: ./infrastructure
        run: |
          echo "Validating Terraform configuration..."
          terraform validate

      - name: Terraform Plan
        working-directory: ./infrastructure
        env:
          TF_VAR_image_tag: ${{ github.sha }}
        run: |
          echo "Planning infrastructure changes..."
          terraform plan -out=tfplan

      - name: Terraform Apply
        working-directory: ./infrastructure
        env:
          TF_VAR_image_tag: ${{ github.sha }}
        run: |
          echo "Applying infrastructure changes..."
          terraform apply -auto-approve tfplan

      - name: Upload training data (retry after S3 creation)
        run: |
          echo "Ensuring training data is uploaded..."
          aws s3 cp Dataset/train_data.csv s3://ml-sentiment-data-${{ env.AWS_ACCOUNT_ID }}/training/train_data.csv --region ${{ env.AWS_REGION }}
          echo "âœ“ Training data uploaded"

      - name: Get deployment outputs
        working-directory: ./infrastructure
        run: |
          echo "==========================================="
          echo "ðŸš€ DEPLOYMENT COMPLETE!"
          echo "==========================================="
          echo ""
          echo "Load Balancer URL:"
          terraform output -raw alb_url
          echo ""
          echo ""
          echo "API Endpoints:"
          echo "  Health:   $(terraform output -raw alb_url)/health"
          echo "  Predict:  $(terraform output -raw alb_url)/predict"
          echo "  Feedback: $(terraform output -raw alb_url)/feedback"
          echo "  Models:   $(terraform output -raw alb_url)/models"
          echo ""
          echo "S3 Buckets:"
          echo "  Models: $(terraform output -raw s3_models_bucket)"
          echo "  Data:   $(terraform output -raw s3_data_bucket)"
          echo ""
          echo "SageMaker Endpoint:"
          terraform output -raw sagemaker_endpoint_name
          echo ""
          echo "==========================================="

      - name: Test health endpoints
        run: |
          echo "Waiting 60 seconds for services to start..."
          sleep 60
          
          echo "Testing ALB health endpoint..."
          ALB_URL=$(cd infrastructure && terraform output -raw alb_url)
          
          for i in {1..10}; do
            if curl -f "$ALB_URL/health" 2>/dev/null; then
              echo "âœ“ Health check passed!"
              exit 0
            fi
            echo "Attempt $i failed, retrying in 30 seconds..."
            sleep 30
          done
          
          echo "âš  Services are starting (this may take a few minutes)"
          echo "âš  Check ECS console for service status"
